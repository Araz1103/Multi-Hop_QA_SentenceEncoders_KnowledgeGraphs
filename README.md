# Multi-Hop_QA_SentenceEncoders_KnowledgeGraphs
This is the official repository for the Capstone Project for Araz Sharma, Rudra Prasad Baksi &amp; Pranav Raj, for Btech 2022 CSE, PES University, Bangalore


Our domain is the popular problem of Question Answering. QA has been a long-term focus in artificial intelligence that can date back to the 1960s. This is also popularly known as Machine Reading Comprehension. The task here is to answer questions based on a given comprehension, which is essentially a textual document of a length of a certain number of paragraphs. This is similar to the Comprehension Based Questions given in examinations, to students across the world. Our work aims to explore how different sentence embeddings can be used, on a similarity of sentences level basis, to answer multi-hop questions from the Multi-RC Dataset. We have done a comparative study between 3 popular sentence embeddings â€“ USE, Siamese BERT \& InferSent. We have also generated Knowledge Graphs for the comprehensions, to try to leverage Graph Convolutions, to enrich embeddings, to find the answer sentences for the Multi-RC Dataset. Our work suggests, that we can use Graph Neural Networks with pre-trained sentence embeddings, like USE, to answer Multi-Hop QA, in the future, to surpass the current benchmarks. 
